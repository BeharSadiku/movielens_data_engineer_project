[core]
dags_folder = ./dags
plugins_folder = ./plugins
executor = SequentialExecutor
parallelism = 32
max_active_tasks_per_dag = 16
max_active_runs_per_dag = 16
load_examples = True
default_timezone = utc
enable_xcom_pickling = False
donot_pickle = True
dag_discovery_safe_mode = True
fernet_key = ${AIRFLOW__CORE__FERNET_KEY}   # load from env

[database]
sql_alchemy_conn = ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}  # use env variable
sql_alchemy_pool_enabled = False
sql_alchemy_pool_size = 5
sql_alchemy_max_overflow = 10
sql_alchemy_pool_recycle = 1800
sql_alchemy_pool_pre_ping = True
load_default_connections = True
check_migrations = True
max_db_retries = 3

[logging]
base_log_folder = ./logs
remote_logging = False
logging_level = INFO
fab_logging_level = WARNING
colored_console_log = True
file_task_handler_new_folder_permissions = 0o775
file_task_handler_new_file_permissions = 0o664
dag_processor_log_target = file
dag_processor_manager_log_location = ./logs/dag_processor_manager/dag_processor_manager.log

[webserver]
web_server_host = 0.0.0.0
web_server_port = 8080
base_url = http://localhost:8080
default_ui_timezone = UTC
config_file = ./webserver_config.py

[secrets]
use_cache = False
cache_ttl_seconds = 900

[metrics]
statsd_on = False
statsd_host = localhost
statsd_port = 8125
statsd_prefix = airflow

[cli]
api_client = airflow.api.client.local_client
endpoint_url = http://localhost:8080

[operators]
default_owner = airflow
default_queue = default
default_cpus = 1
default_ram = 512
default_disk = 512
default_gpus = 0

[debug]
fail_fast = False

[api]
enable_experimental_api = False
auth_backends = airflow.api.auth.backend.session
maximum_page_limit = 100
fallback_page_limit = 100
enable_xcom_deserialize_support = False
